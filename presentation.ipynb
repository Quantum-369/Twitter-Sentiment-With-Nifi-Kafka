{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"presentation.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"30147e2a"},"source":["# <font color=blue><center>Live Dashboard - Twitter Sentiment Analysis</center></font>\n","## Agenda\n","### Architecture\n","- Overview of data flow\n","- Tech Stack\n","- End result\n","\n","### Environment Setup\n","- AWS EC2 instance and security group creation\n","- Docker installation and running\n","- Usage of docker-composer and starting all the tools\n","- How to access tools in local machine\n","\n","### Model Creation\n","- Dataset exploration and bucketizing\n","- Stratified sampling and dataset splitting\n","- Feature extraction and pipeline creation\n","- Model training and evaluation\n","- Saving model and application\n","\n","### Extraction\n","- Streaming data from Twitter API using NiFi\n","- Creating Kafka topic and publishing messages to it\n","\n","### Transformation and Load\n","- Schema extraction from the stream of Tweets\n","- Reading data from Kafka as Streaming Dataframe\n","- Extraction and cleansing of Twitter data\n","- Sentiment analysis of tweet\n","- Continuous data load to MongoDB\n","\n","### Visualization\n","- Scatter graph and Table definition with python Dash with intervals\n","- Graph and Table app call-back\n","\n","### Code walkthrough\n","- Schema Generator\n","- SentimentAnalyzer\n","- StreamListener\n","- SentimentVisualizer"],"id":"30147e2a"},{"cell_type":"markdown","metadata":{"id":"e7eaf504"},"source":["## <font color=blue>Architecture</font>\n","### Overview of data flow\n","#### Data Flow Architecture\n","![alt text](live_dashboard_-_twitter_sentiment_analysis.png)\n","### Tech Stack\n","* AWS EC2\n","* Docker\n","* Jupyter Lab\n","* Spark Structured Streaming and MLlib\n","* NiFi\n","* Kafka\n","* Python\n","* MongoDB\n","* Plotly\n","* Dash\n","\n","### End result\n","#### NiFi Processor Setup\n","![alt text](nifi.PNG)\n","#### Tweets Stored in MongoDB\n","![alt text](mongo.PNG)\n","#### Live Dashboard\n","![alt text](dash.PNG)"],"id":"e7eaf504"},{"cell_type":"markdown","metadata":{"id":"bd740e6f"},"source":["## <font color=blue>Environment Setup</font>\n","### AWS EC2 instance and security group creation\n","- t2.xlarge instance\n","- 32GB of storage recommended\n","- Allow ports 4000 - 38888\n","- Connect to ec2 via ssh\n"," <code>ssh -i \"D:\\path\\to\\private\\key.pem\" user@Public_DNS</code>\n"," <br/>Example:<code>ssh -i \"D:\\Users\\pyerravelly\\Desktop\\twitter_analysis.pem\" ec2-user@ec2-54-203-235-65.us-west-2.compute.amazonaws.com</code><br/>\n","- Port forwarding \n"," <code>ssh -i \"D:\\path\\to\\private\\key.pem\" user@Public_DNS</code>\n"," <br/>Example:<code>ssh -i \"D:\\Users\\pyerravelly\\Desktop\\twitter_analysis.pem\" ec2-user@ec2-34-208-254-29.us-west-2.compute.amazonaws.com -L 2081:localhost:2041 -L 4888:localhost:4888 -L 2080:localhost:2080 -L 8050:localhost:8050 -L 4141:localhost:4141</code><br/>\n","- Copy from local to ec2\n","  <code>scp -r -i \"D:\\Users\\pyerravelly\\Desktop\\twitter_analysis.pem\"</code>\n","  <br/>Example:<code>scp -r -i \"D:\\Users\\pyerravelly\\Desktop\\twitter_analysis.pem\" D:\\Users\\pyerravelly\\Downloads\\spark-standalone-cluster-on-docker-master\\build\\docker\\docker-exp ec2-user@ec2-34-208-254-29.us-west-2.compute.amazonaws.com:/home/ec2-user/docker_exp\n","</code>\n","\n","### Docker installation and running\n","    \n","### Usage of docker-composer and starting all the tools\n","\n","- Commands to install Docker\n","\n","<code>sudo yum update -y</code>\n","<code><br/>sudo yum install docker</code>\n","<code><br/>sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose</code>\n","<code><br/>sudo chmod +x /usr/local/bin/docker-compose</code>\n","<code><br/>sudo gpasswd -a $USER docker</code>\n","<code><br/>newgrp docker</code>\n","<br/>Start Docker: <code>sudo systemctl start docker</code>\n","<br/>Stop Docker: <code>sudo systemctl stop docker</code>\n","\n","- How to access tools in local machine <br/>\n","    List Docker containers running: <code>docker ps</code><br/>\n","    CLI access in Docker container: <code>docker exec -i -t docker_kafka_1 bash</code><br/>\n","    NiFi at: http://localhost:2080/nifi/ <br/>\n","    Mongo Express at: http://localhost:4141/ <br/>\n","    Jupyter Lab at: http://localhost:4888/lab? <br/>"],"id":"bd740e6f"},{"cell_type":"markdown","metadata":{"id":"6523b815"},"source":["## <font color=blue>Model Creation</font>\n","### Classification\n","- supervised machine learning algorithms that identify which category an item belongs to\n","- feature and label\n","\n","### Dataset exploration and bucketizing\n","- http://jmcauley.ucsd.edu/data/amazon/\n","- reviewText — text of the review\n","  \n","  overall — rating of the product\n","  \n","  summary — summary of the review\n","- Bucketize dataset to lable whether features are positive or negative\n","\n","### Stratified sampling and dataset splitting\n","- partitioning data to homogeneous sample and making sensitive to negative labels\n","- split stratified sample to 80% training data and 20% test data\n","\n","### Feature extraction and pipeline creation\n","- Tokenizing, removing stop words, TF-IDF(Count Vectorixzation, IDF) and Logistic Regression\n","- Create pipeline to train the model\n","\n","### Model training and evaluation\n","- Training model with the data prepared\n","- Evaluation of model with Binary Classification Evaluator\n","\n","### Saving model and application\n","- Save classification model\n","- Example application of created model"],"id":"6523b815"},{"cell_type":"markdown","metadata":{"id":"c85d6007"},"source":["## <font color=blue>Extraction</font>\n","### Nifi\n","- Processor\n","- Connection\n","\n","### Twitter App Creation\n","- Goto https://developer.twitter.com/en/portal/projects-and-apps\n","\n","### Streaming data from Twitter API using NiFi\n","- Nifi Setup\n","\n","### Kafka\n","- Topic\n","- Publish\n","- Subscribe\n","\n","### Topic and publishing messages to it\n","- Topic creation through CLI\n","- Publish tweets via NiFi\n","\n","#### Commands\n","<code>docker ps</code> to get kafka container name\n","\n","<code>docker exec -i -t docker_kafka_1 bash</code> enter into kafka CLI\n","\n","<code>kafka-topics.sh --create --topic tweets --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:2181</code> creation of topic named tweets\n","\n","<code>kafka-console-consumer.sh --bootstrap-server localhost:29092 --topic twitter_demo --from-beginning --max-messages 30</code> consume/read data from topic"],"id":"c85d6007"},{"cell_type":"markdown","metadata":{"id":"402a9a13"},"source":["## <font color=blue>Transformation and Load</font>\n","### Read Streaming Data and Cleansing\n","- Schema extraction from the stream of Tweets\n","- Reading data from Kafka as Streaming Dataframe\n","- Extraction and cleansing of Twitter data\n","- Sentiment analysis of tweet\n","\n","### Writing data to MongoDB\n","- Continuous data load to MongoDB"],"id":"402a9a13"},{"cell_type":"markdown","metadata":{"id":"ca51eb02"},"source":["## <font color=blue>Visualization</font>\n","- Scatter graph and Table definition with intervals using Python Plotly and Dash\n","- Graph and Table app call-back"],"id":"ca51eb02"},{"cell_type":"markdown","metadata":{"id":"83dad3d3"},"source":["## <font color=blue>Code walkthrough</font>\n","- Schema Generator\n","- SentimentAnalyzer\n","- StreamListener\n","- SentimentVisualizer"],"id":"83dad3d3"}]}